{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellChecker:\n",
    "    def __init__(self, dict_path):\n",
    "        self.dict_path  = dict_path\n",
    "        self.word_dict = self.load_dict(self.dict_path)\n",
    "    \n",
    "    \n",
    "    def store_words(self, word_list):\n",
    "        word_dict = {}\n",
    "        \n",
    "        for word in word_list:\n",
    "            key = word[0]\n",
    "            if key not in word_dict.keys():\n",
    "                word_dict[key] = []\n",
    "            word_dict[key].append(word)\n",
    "            \n",
    "        for key in word_dict.keys():\n",
    "            word_dict[key] = sorted(word_dict[key])\n",
    "        return word_dict\n",
    "    \n",
    "    def load_dict(self, dict_path):\n",
    "        word_list = []\n",
    "        with open(dict_path,errors=\"ignore\") as file:\n",
    "            word_list = file.read().splitlines()\n",
    "            \n",
    "        return self.store_words(word_list)\n",
    "    \n",
    "    def add(self, word):\n",
    "        key = word[0]\n",
    "        self.word_dict[key].append(word)\n",
    "        self.word_dict[key] = sorted(self.word_dict[key])\n",
    "    \n",
    "    def get_nearest(self, word, nearest = 4):\n",
    "        nearest_words = []\n",
    "        key = word[0]\n",
    "        \n",
    "        if word in self.word_dict[key]:\n",
    "            return [word]\n",
    "        \n",
    "        augmented_sublist = self.word_dict[key].copy()\n",
    "        target_idx = bisect.bisect_left(augmented_sublist, word)\n",
    "        \n",
    "        if target_idx < 2:\n",
    "            nearest_words = augmented_sublist[:target_idx+2]\n",
    "            \n",
    "            prev_key = chr(ord(key) - 1)\n",
    "            while prev_key in self.word_dict.keys():\n",
    "                for word in self.word_dict[next_key]:\n",
    "                    nearest_words.append(word)\n",
    "                    if len(nearest_words) == 4:\n",
    "                        return nearest_words\n",
    "                prev_key = chr(ord(prev_key) - 1)\n",
    "            return nearest_words\n",
    "        \n",
    "        elif target_idx > len(augmented_sublist) - 1:\n",
    "            nearest_words = augmented_sublist[target_idx:]\n",
    "            \n",
    "            next_key = chr(ord(key)+1)\n",
    "            while next_key in self.word_dict.keys():\n",
    "                for word in self.word_dict[next_key]:\n",
    "                    nearest_words.append(word)\n",
    "                    if len(nearest_words) == 4:\n",
    "                        return nearest_words\n",
    "                next_key = chr(ord(next_key)+1)\n",
    "            return nearest_words\n",
    "            \n",
    "        else:\n",
    "            nearest_words = augmented_sublist[target_idx-2:target_idx+2]\n",
    "            return nearest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpellChecker('./dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ƒclat', 'ƒlan', 'ƒmigrƒs', 'ƒpoque']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.word_dict['ƒ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.add('ƒaaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ƒaaaa', 'ƒclat', 'ƒlan', 'ƒmigrƒs', 'ƒpoque']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.word_dict['ƒ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ƒaaaa', 'ƒclat']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.get_nearest('ƒaaa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure used to store the dictionary is the same as real language dictionaries. In other words, A hash-map where the key is the first letter of the word and the value is array containing all words starts with this letter.\n",
    "\n",
    "    - dictionary = {\n",
    "                    'a' : ['aa',..., 'aaes'],\n",
    "                    'b' : ['bb',...,'bsfda'],\n",
    "                     .\n",
    "                     .\n",
    "                     .\n",
    "                     'z':['zads',...,'zasd'],\n",
    "                    }\n",
    "                    \n",
    "reasons to use this data-structure:\n",
    "        - Search operation in hash-map is O(1), so using hash-map will be suitable for search operations.\n",
    "        - words can't be keys themselves as hash-map are (keys, values)\n",
    "        - Having the values as arrays help us in traversing the dictionary in lexographically order. This can be done by sorting each value array. While the sorting of the keys can be infered --> the values of 'a' becomes earlier than values of 'c'.\n",
    "        \n",
    "\n",
    "complexity of operations:\n",
    "    - add: O(1). Since the list is dynamic in python, the cost of n .append() operations is n. In other words, the amortized cost is O(1).\n",
    "    \n",
    "    - get_nearest: if word is not in the dictionary,\n",
    "         - copy the target list --> O(n) ; n is the number of words starts with same start character of passed word\n",
    "         - bisect_left uses binary search --> O(log n)\n",
    "         - best case: the 4 nearest words in the target array --> slicing the array O(n+4)\n",
    "           other cases: one or two of the nearest words are in previous or next characters --> a while loop that in worst case will be of constant iterations and constant .append() operations --> ~ O(n+4)\n",
    "        \n",
    "        -over all complexity O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other approaches\n",
    "\n",
    "Other approaches will be manily revolving around which data-structure used to store the dictionary. Other methods will depend on that choice. So. let's discuss other data-structures:\n",
    "\n",
    "1- List\n",
    "     - if all the words are stored in one list, the search process will be O(n) where n is the total number of words in the dictionary. Obviously, a bas idea.\n",
    "     \n",
    "2- Hashmap(dictionary)\n",
    "    - every words is a key, so search is of O(1). But no sorting is guranteed. not feasible for the task\n",
    "    \n",
    "3- Nested dictionaries\n",
    "    - Level 1: where key is fist letter and value is list of all words begin with this letter. (used)\n",
    "    - Level 2: where for each key there is another dictionaries. This will make search for a word faster, but searching lexographically is more exhausting, and more memory is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
